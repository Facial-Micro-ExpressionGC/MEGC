<!DOCTYPE html>
<head>
	<title>Facial-Micro-Expression-Grand-challenge</title>
    <meta charset="UTF-8">
	<meta name="keywords" content="" />
	<meta name="description" content="" />
    <!-- 
    Division Template
    http://www.templatemo.com/preview/templatemo_448_division
    -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link href="css/templatemo_style.css" rel="stylesheet" type="text/css">
</head>
<body>
	<div class="main-container">
		<div class="col-xs-12 visible-sm visible-xs" id="templatemo_mobile_menu_wap">
			<p id="mobile_menu_btn"> <a href="#"><span class="fa fa-bars"></span></a> </p>
			<div id="mobile_menu">
				<ul class="nav nav-pills nav-stacked navbar-collapse in">
					<li id="page1_link_m" class="active">Home</li>
					<li id="page2_link_m">Submissions</li>
					<li id="page3_link_m">Organizers</li>
					<li id="page4_link_m">About</li>
					<li id="page5_link_m">Speakers</li>
					<li id="page6_link_m">Contact</li>
					<li><a href="http://www.google.com" class="external">External</a></li>
				</ul>
			</div>
		</div>
		<div class="templatemo-header">
			<div id="logo" class="pull-left">MEGC2019</div>
			<nav class="hidden-sm hidden-xs pull-right">			
				<ul>
					<li id="page1_link_m" class="active">Home</li>
					<li id="page2_link_m">About</li>
					<li id="page3_link_m">Submissions</li>
					<li id="page4_link_m">Organizers</li>
					<li id="page5_link_m">Speakers</li>
					<li id="page6_link_m">Contact</li>
					<li><a href="http://www.google.com" class="external">External</a></li>
				</ul>
			</nav>
		</div>

		<section class="page" id="page1">
			<h1 class="hide">Home</h1>
			<div id="slider-controls">
				<!--Thumbnail Navigation-->
				<div id="prevthumb"></div>
				<div id="nextthumb"></div>
				
				<!--Arrow Navigation-->
				<a id="prevslide" class="load-item"></a>
				<a id="nextslide" class="load-item"></a>
				
				<div id="thumb-tray" class="load-item">
					<div id="thumb-back"></div>
					<div id="thumb-forward"></div>
				</div>
				
				<!--Time Bar-->
				<div id="progress-back" class="load-item">
					<div id="progress-bar"></div>
				</div>
				
				<!--Control Bar-->
				<div id="controls-wrapper" class="load-item">
					<div id="controls">
						
						<a id="play-button"><img id="pauseplay" src="images/pause.png" alt="Play, pause button"/></a>

						<!--Slide counter-->
						<div id="slidecounter">
							<span class="slidenumber"></span> / <span class="totalslides"></span>
						</div>
						
						<!--Slide captions displayed here-->
						<div id="slidecaption"></div>
						
						<!--Thumb Tray button-->
						<a id="tray-button"><img id="tray-arrow" src="images/button-tray-up.png" alt="Thumb tray button"/></a>
						
						<!--Navigation-->
						<ul id="slide-list"></ul>						
					</div>
				</div><!--/Thumbnail Navigation-->
			</div>				
		</section>	
		<section class="page" id="page2">
			<div class="page-container">
				<div class="page-content padding">
					<h1>About Us</h1>
					<p> Workshop Title</p>

					<p>The Second Facial Micro-Expression Grand Challenge (MEGC): Spotting and Recognition</p>

					<p>Workshop motivation, expected outcomes and impact</p>

<p>Facial micro-expressions (MEs) are involuntary movements of the face that occur spontaneously when a person experiences an emotion but attempts to suppress or repress the facial expression, typically found in a high-stakes environment. As such, the duration of MEs is very short with the general duration of not more than 500 milliseconds (ms), and is the telltale sign that distinguishes them from a normal facial expression. Computational analysis and automation of tasks on micro-expressions is an emerging area in face research, with a strong interest appearing as recent as 2014. Only recently, the availability of a few spontaneously induced facial micro-expression datasets has provided the impetus to advance further from the computational aspect. Particularly comprehensive

are two state-of-the-art FACS coded datasets: the Chinese Academy of Sciences Micro-Expression Database II (CASME II) with 247 MFEs at 200 fps and the Spontaneous Facial Micro-Movement Dataset (SAMM) with 159 MFEs at 200 fps. In addition, there is recent interest in acquiring “in-the-wild” datasets to further introduce real-world scenarios. While much research has been done on these datasets individually, there have been little attempts to introduce a more rigorous and realistic evaluation to work done in this domain.

This is the second edition of this workshop, which aims to promote interactions between researchers and scholars not only from within this niche area of facial micro-expression research, but also including those from broader, general areas of expression and psychology research.</p>

					<p> This workshop has two main agenda:</p>
				<ul>
					<li>To organize the Second Grand Challenge for facial micro-expression research, involving cross-database recognition and spotting of micro-expressions,

</li>
					<li>To solicit original works that address a variety of challenges of ME research, but not limited to</li>
					<li></li>
					<li></li>
					<li></li>
					<li></li>
					<li><</li>
				</ul>
					<ul>
						<li>ME spotting/detection</li>
						<li>ME recognition</li>
						<li>ME feature representation and computational analysis</li>
						<li>Unified ME spot-and-recognize schemes</li>
						<li>Deep learning techniques for MEs spotting and recognition</li>
						<li>MEs data analysis and synthesis</li>
						<li>New datasets for MEs</li>
						<li>Psychology of MEs</li>
					</ul>
						
<a href="#">free website template</a> that can be used for any purpose.<br><br>Aliquam iaculis lectus accumsan, egestas lorem ac, malesuada purus. Aenean in tincidunt libero. Etiam vitae dolor vel justo temllicitudin. Sed fermentum, neque in dignissim aliquam, quam ante pellentesque quam, posuere eros purus purus. Ut non est magna.</p>
					<!--<img src="images/about/about2.jpg" alt="about" class="bordered">-->
				</div>				
			</div>	    
		</section>
		
		<section class="page services" id="page3">
			<h1>Submissions</h1>
			<div class="page-container">
				<div class="templatemo-item">
					<!-- To change icons, see http://fortawesome.github.io/Font-Awesome/icons/ -->
					<i class="fa fa-cog rounded"></i>
					<h3>Easy Customization</h3>
					<p>Division is free responsive template provided by templatemo.com website. Feel free to use this template for your website.</p>
				</div>
				<div class="templatemo-item">
					<i class="fa fa-html5 rounded"></i>
					<h3>Web Design</h3>
					<p>Please inform your friends about our website. Thank you for visiting us. You may contact us instantly if you have anything to say.</p>
				</div>
				<div class="templatemo-item">
					<i class="fa fa-star rounded"></i>
					<h3>High Quality</h3>
					<p>Edit js/templatemo_script.js file in your HTML editor for the footer text line which is located on line number 33. Good Luck!</p>
				</div>
				<div class="templatemo-item">
					<i class="fa fa-cubes rounded"></i>
					<h3>Professional Design</h3>
					<p>Morbi id nisi enim. Ut congue interdum pharetra facilisi. Aenean consectetur pellentesque mauris nec ornare. Nam tortor just, condimentum.</p>
				</div>
				<div class="templatemo-item">
					<i class="fa fa-database rounded"></i>
					<h3>User Experience</h3>
					<p>Nulla in nunc elit. Etiam et felis molestie fermentum. Ut quis diam porttitor, volutpat nulla. Phasellus egestas eu lacus eu pharetra.</p>
				</div>
				<div class="templatemo-item">
					<i class="fa fa-mobile rounded"></i>
					<h3>Mobile Friendly</h3>
					<p>Nulla in nunc elit. Etiam et felis molestie fermentum. Ut quis diam porttitor, dictum dolor in. Phasellus egestas eu lacus eu pharetra.</p>
				</div>
			</div>			
		</section>
		<section class="page team" id="page4">
			<h1>Organizers</h1></br>
			<h1>List of organizers including affiliation, email address, and short bio</h1>
			<div class="page-container">
				<div class="templatemo-item">
					<img src="images/team/Moi.jpeg" alt="Team member 1" class="bordered">
					<h3>Moi Hoon Yap</h3>		
	<p>Manchester Metropolitan University,UK, m.yap@mmu.ac.uk<br />
	Moi Hoon Yap received her PhD in Computer Science from Loughborough University in 2009.<br />
	She is a Reader (Associate Professor) in Computer Vision at the Manchester Metropolitan University and a Royal Society Industry Fellow with Image Metrics Ltd.<br />
	She leads the Human-Centred Computing Group and the lead contributor of SAMM dataset.<br />
	Her research is funded by The Royal Society, EU funding, Innovate UK and industrial funding.<br />
	Her research expertise is in computer vision, deep learning, image/video processing on face and gesture analysis.</p>


					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>                	
				</div>
				<div class="templatemo-item">
					<img src="images/team/Su-Jing.jpg" alt="Team member 2" class="bordered">
					<h3>Sujing Wang</h3>
	 <p>Chinese Academy of Sciences, China, wangsujing@psych.ac.cn.<br />
	 Sujing Wang received his Master's degree from the Software College of Jilin University, Changchun, China, in 2007.<br />
	 He received the Ph.D. degree from the College of Computer Science and Technology of Jilin University in 2012.<br />
         He was a postdoctoral researcher in Institute of Psychology, Chinese Academy of Sciences from 2012 to 2015.<br />
	 He is now an Associate Researcher in Institute of Psychology, Chinese Academy of Sciences.<br />
         He has published more than 50 scientific papers.<br />
         He is One of Ten Selectees of the Doctoral Consortium at International Joint Conference on Biometrics 2011.<br />
	 He was called as Chinese Hawkin by the Xinhua News Agency. His current research interests include pattern recognition,<br /> 
	 computer vision and machine learning. He serves as an associate editor of Neurocomputing (Elsevier).</p>

					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>    
				</div>
				<div class="templatemo-item">
					<img src="images/team/member3.jpg" alt="Team member 3" class="bordered">
					<h3>John See</h3>
	<p>Multimedia University, Malaysia, johnsee@mmu.edu.my<br/>
	John See received his PhD in Computer Science, MEngSc and BEng degrees from Multimedia University (MMU), Malaysia.<br />
	He is currently a Senior Lecturer at Multimedia University where he leads the Visual Processing Laboratory under the Centre for Visual Computing.<br />
	He is also currently a Visiting Research Fellow to Shanghai Jiao Tong University, China.<br />
	Dr. See has published more than 50 articles in reputable journals and conferences such as IEEE T-AC, IEEE T-CE, ICCV, ICIP, ACCV, and FG,<br />
	and has also served as chair of several workshops and special sessions in various international computer vision and signal processing conferences worldwide.<br />
	He will be serving as Program Chair in IEEE MMSP 2019. His research interests cover a diverse range of topics in computer vision and pattern recognition, <br />
	particularly in the emerging fields of facial biometrics, affective computing, computational aesthetics and deep learning.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>
				</div>
				<div class="templatemo-item">
					<img src="images/team/member2.jpg" alt="Team member 2" class="bordered">
					<h3>Xiaopeng Hong,</h3>
					<p>University of Oulu, Finland, hongxiaopeng.cn@gmail.com</p>
					<p>Xiaopeng Hong received his BEng and Ph.D. degrees in computer application and technology from Harbin Institute of Technology, Harbin, P. R. China, in 2004 and 2010 respectively. He is currently a Docent with the Center for Machine Vision and Signal Analysis, University of Oulu, Finland, where he has been a scientist researcher since 2011. Dr. Hong has published over 30 articles in mainstream journals and conferences such as IEEE T-PAMI, IEEE T-IP, IEEE CVPR and ACM UbiComp, and have one issued Chinese Patent. He has organized two international workshops and served as a reviewer for about 30 journals and conferences. His current research interests include the deep learning technology and other machine learning methods, especially their applications in multi-modal learning, affective computing, intelligent medical examination, and human-computer interaction, etc. His research has been reported by global media including MIT Technology Review and Daily Mail.</p
</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>                	
				</div>
				<div class="templatemo-item">
					<img src="images/team/member3.jpg" alt="Team member 3" class="bordered">
					<h3>Developer</h3>
					<p>Ut quis diam porttitor, dictum dolor in, volutpat nulla porttitor.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>    
				</div>
				<div class="templatemo-item">
					<img src="images/team/member1.jpg" alt="Team member 1" class="bordered">
					<h3>Designer</h3>
					<p>Praesent id mauris eu urna vehicula rutrum sed in elit.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>
				</div>
			</div>			
		</section>
		<section class="page contact" id="page5">
			<div class="page-container">
				<div class="page-content padding">
					<h1>Contact Us</h1>
					<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Asperiores, itaque vero facere laudantium voluptas temporibus mollitia nisi deleniti illo minima quisquam corporis possimus nesciunt. Accusantium modi dolores in ex officiis!</p>
							
				</div>							
			</div> 			       	                
		</section>

                <section class="page contact" id="page6">
			<div class="page-container">
				<div class="page-content padding">
					<h1>Contact Us</h1>
					<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Asperiores, itaque vero facere laudantium voluptas temporibus mollitia nisi deleniti illo minima quisquam corporis possimus nesciunt. Accusantium modi dolores in ex officiis!</p>
					<div class="map-contact-container">
						<div id="map"></div>
						<div class="contact-form">
							<form>
								<input type="text" name="name" id="name" placeholder="Name">
								<input type="email" name="email" id="email" placeholder="Email">
								<input type="text" name="subject" id="subject" placeholder="Subject">
								<textarea name="comments" id="comments" placeholder="Message"></textarea>
								<button type="submit">SEND</button>
							</form>		
						</div>	
					</div>		
				</div>							
			</div> 			       	                
		</section>
		<!-- footer code is injected from "js/templatemo_script.js", change at line 32 -->
	</div>
	<script src="js/jquery-1.11.1.min.js"></script>	
	<script src="js/jquery.easing-1.3.js"></script>
	<script src="js/plugins.js"></script>
	<script type="text/javascript">
    	/* www.buildinternet.com/project/supersized 
    	------------------------------------------- */
    	jQuery(function ($) {	
		// load gallery
		$.supersized({
		        // Functionality
		        slide_interval: 5000, // Length between transitions
		        transition: 1, // 0-None, 1-Fade, 2-Slide Top, 3-Slide Right, 4-Slide Bottom, 5-Slide Left, 6-Carousel Right, 7-Carousel Left
		        transition_speed: 700, // Speed of transition

		        // Components                           
		        slide_links: 'blank', // Individual links for each slide (Options: false, 'num', 'name', 'blank')
		        slides: [ // Slideshow Images
		        {
		        	image: 'images/slider/slide-1.jpg', title: 'Image 1', thumb : 'images/slider/thumb-1.jpg'
		        }, {
		        	image: 'images/slider/slide-2.jpg', title: 'Image 2', thumb : 'images/slider/thumb-2.jpg'
		        }, {
		        	image: 'images/slider/slide-3.jpg', title: 'Image 3', thumb : 'images/slider/thumb-3.jpg'
		        }, {
		        	image: 'images/slider/slide-4.jpg', title: 'Image 4', thumb : 'images/slider/thumb-4.jpg'
		        }, {
		        	image: 'images/slider/slide-5.jpg', title: 'Image 5', thumb : 'images/slider/thumb-5.jpg'
		        }
		        ]

		    });
});
</script>
<script src="js/bootstrap.min.js"></script>
<script src="js/templatemo_script.js"></script>
</body>
</html>
